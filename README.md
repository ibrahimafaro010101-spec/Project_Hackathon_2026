# INTELLIGENT ANALYTICS HACKATHON - 2026

**_Team UM6P_**

Ibrahima FARO [[ibrahima.faro@um6p.ma](mailto:ibrahima.faro@um6p.ma)],

Aya ALAMI [[aya.alami@um6p.ma](mailto:aya.alami@um6p.ma)],

Mariam DIAKITE [[mariam.diakite@um6p.ma](mailto:mariam.diakite@um6p.ma)],

Babacar Sanding [[babacar.sanding@um6p.ma](mailto:babacar.sanding@um6p.ma)]

**_R√©ferents de la Team_**

El Gargouh Younes & Nadif Firdaouss

**Profilage et gestion des clients √† risque dans une assurance Automobile**

---
## Table des mati√®res

* [Contexte](#contexte)
* [Justification du choix du secteur de l'Automobile](#justification-du-choix-du-secteur-de-lautomobile)
* [Objectif global](#objectif-global)
* [Probl√©matique centrale](#probl√©matique-centrale)
* [Ambition](#ambition)
* [Donn√©es d'entrainement](#donn√©es-dentrainement)
* [Approche generale et architecture](#approche-generale-et-architecture)
  * [Pr√©paration & qualit√© des donn√©es](#pr√©paration--qualit√©-des-donn√©es)
  * [NLQ Engine](#nlq-engine)
  * [Insight AI](#insight-ai)
  * [Mod√®les Pr√©dictifs](#mod√®les-pr√©dictifs)
* [Timeline du projet](#timeline-du-projet)
* [Choix des outils, technologies et packages](#choix-des-outils-technologies-et-packages)

---
## Contexte

Ce projet, d√©velopp√© par la Team UM6P dans le cadre du Hackathon DXC ‚ÄúIntelligent Analytics‚Äù, s‚Äôinscrit dans un mouvement global de transformation des organisations par la donn√©e et l‚Äôintelligence artificielle. Dans de nombreux secteurs, les d√©cideurs doivent g√©rer des volumes croissants de donn√©es, tout en faisant face √† une exigence accrue de rapidit√©, de tra√ßabilit√© et d‚Äôefficacit√© dans la prise de d√©cision. Cependant, les approches traditionnelles restent souvent descriptives et r√©actives, et produisent des analyses a posteriori qui mobilisent fortement les √©quipes techniques. L‚Äôanalytics intelligent vise au contraire √† automatiser la pr√©paration des donn√©es, acc√©l√©rer l‚Äôacc√®s √† l‚Äôinformation (y compris via des interfaces en langage naturel) et renforcer les d√©cisions gr√¢ce √† des mod√®les pr√©dictifs et des recommandations actionnables. Cette dynamique est particuli√®rement importante dans les activit√©s o√π l‚Äôincertitude, la variabilit√© des comportements et les arbitrages √©conomiques imposent une gestion proactive du risque et de la performance

## Justification du choix du secteur de l'Automobile

Dans le rapport de s√©curit√© routi√®re Maroc de l'observatoire national de la s√©curit√© routi√®re [1](https://www.narsa.ma/sites/default/files/2024-11/Rapport%20de%20la%20SR%202022%20V5_231020_140005_compressed.pdf%7D$), le choix du secteur de l‚Äôassurance automobile est particuli√®rement solide et int√©ressant pour 3 raisons : impact, volume de donn√©es, valeur business imm√©diate.

Le rapport souligne que le Maroc a enregistr√© 113 625 accidents corporels en 2022, avec 3 499 d√©c√®s. Ce niveau de mortalit√© d√©passait l‚Äôobjectif interm√©diaire de la strat√©gie nationale (objectif < 2 643 tu√©s en 2022). Ce r√©sultat permet de remarquer que le secteur de l‚Äôautomobile pr√©sente un risque fr√©quent et co√ªteux, parfaitement align√© avec une solution IA ‚ÄúIntelligent Analytics‚Äù centr√©e sur pr√©vention - tarification - pilotage, et surtout dans la proposition des recommandations.

Le rapport insiste sur le fait que des donn√©es fiables sont un levier cl√© pour : comprendre les causes, cibler les facteurs de risque, √©valuer l‚Äôimpact des interventions, et prendre des d√©cisions fond√©es sur des preuves. C‚Äôest exactement ce qu'on compte faire dans ce projet : *transformer des historiques de contrats en indicateurs (prime/jour, loss ratio, risque client, fraude‚Ä¶) puis en d√©cisions.*

Du point de vue du poids √©conomique, le rapport rappelle que les accidents routiers repr√©sentent un fardeau √©conomique estim√© √† environ 3\% du PNB des pays et le parc des v√©hicules de tourisme est tr√®s important (44,7\% du parc national, et 50,91\% des v√©hicules impliqu√©s dans les accidents corporels sont des v√©hicules de tourisme). Ainsi, le march√© auto offre beaucoup de contrats, beaucoup d‚Äôexpositions, donc beaucoup de donn√©es et de gains potentiels (meilleure segmentation, meilleure prime, meilleure pr√©vention, meilleure gestion sinistres).

En Afrique, ces enjeux sont encore plus critiques. Le continent affiche le taux de mortalit√© routi√®re le plus √©lev√© au monde, avec environ 19,6 d√©c√®s pour 100 000 habitants, contre une moyenne mondiale d‚Äôenviron 15 pour 100 000 (OMS, ), alors m√™me qu‚Äôil ne repr√©sente qu‚Äôenviron 3\% du parc automobile mondial. Paradoxalement, l‚ÄôAfrique conna√Æt une croissance rapide de la motorisation, port√©e par l‚Äôurbanisation, l‚Äôessor des classes moyennes et le d√©veloppement des activit√©s de transport (Banque mondiale, Africa Transport Outlook). Cette dynamique accro√Æt m√©caniquement l‚Äôexposition au risque automobile, dans des contextes o√π les infrastructures, les syst√®mes de contr√¥le et les m√©canismes assurantiels restent souvent insuffisants.

> Nous avons choisi l‚Äôassurance automobile car c‚Äôest un risque universel, √† forte fr√©quence et √† co√ªts tr√®s variables, ce qui en fait un cas d‚Äôusage id√©al pour l‚ÄôIA. √Ä l‚Äô√©chelle mondiale, les assureurs cherchent √† am√©liorer la rentabilit√© technique (loss ratio), acc√©l√©rer la gestion des sinistres, et mieux piloter la r√©tention client dans un contexte de concurrence et d‚Äô√©volution des co√ªts. En Afrique, la croissance urbaine et l‚Äôintensification des usages (flottes, mobilit√©) rendent l‚Äôexposition au risque plus complexe, tandis que la qualit√© des donn√©es peut √™tre h√©t√©rog√®ne : une solution d‚Äôanalytics intelligent qui nettoie, structure et transforme les donn√©es en indicateurs actionnables (risque, fraude, paiement, r√©siliation) apporte un gain imm√©diat pour la d√©cision m√©tier.

## Objectif global

L‚Äôassurance automobile constitue aujourd'hui un segment strat√©gique mais fortement expos√© au risque pour les assureurs. La hausse des sinistres, l‚Äô√©volution des comportements des assur√©s et l'intensification de la concurrence rendent la gestion du portefeuille plus complexe, tandis que les approches traditionnelles restent souvent descriptives et r√©actives.
Ce projet vise donc √† mobiliser l‚ÄôIA et l‚Äôanalyse avanc√©e des donn√©es pour transformer l‚Äôidentification et la gestion des clients √† risque, en passant d‚Äôune logique a posteriori √† une approche pr√©dictive, proactive et orient√©e d√©cision m√©tier.

## Probl√©matique centrale

Ainsi, afin d‚Äôop√©rationnaliser cet objectif et de cadrer pr√©cis√©ment la contribution du projet, nous formulons la probl√©matique centrale comme suit :
> **Comment anticiper et g√©rer efficacement les clients √† risque dans l‚Äôassurance automobile afin de r√©duire les pertes financi√®res et d‚Äôam√©liorer la qualit√© de la d√©cision m√©tier gr√¢ce √† l‚Äôintelligence artificielle ?**

Cette probl√©matique est au c≈ìur des enjeux actuels du secteur de l‚Äôassurance, o√π la performance d√©pend de plus en plus de la capacit√© √† anticiper les comportements futurs des assur√©s plut√¥t que de simplement constater les √©v√©nements pass√©s. Cette probl√©matique s‚Äôinscrit dans un contexte marqu√© par :

*   une sinistralit√© croissante, li√©e √† l‚Äôaugmentation du parc automobile, √† la densification urbaine et √† l‚Äô√©volution des comportements de conduite, ce qui exerce une pression directe sur la rentabilit√© des assureurs.
*   une r√©siliation √©lev√©e des contrats, notamment dans l‚Äôassurance automobile, o√π les clients sont de plus en plus volatils et sensibles aux prix, rendant la fid√©lisation complexe et co√ªteuse.
*   une forte asym√©trie d‚Äôinformation entre l‚Äôassureur et l‚Äôassur√©, notamment sur les comportements r√©els de conduite, les risques latents ou les intentions de r√©siliation, ce qui complique l‚Äô√©valuation fine du risque.
*   et des d√©cisions encore largement r√©actives plut√¥t que pr√©dictives fond√©es sur des r√®gles fixes ou des analyses descriptives, qui interviennent souvent apr√®s la survenance du sinistre ou la perte du client, au lieu d‚Äôagir en amont.

## Ambition

L‚Äôambition qui nous anime est de renforcer la capacit√© d√©cisionnelle des acteurs de l‚Äôassurance automobile, en leur fournissant des outils capables de d√©tecter les signaux faibles, d‚Äôanticiper les risques et d‚Äôorienter les strat√©gies de tarification, de fid√©lisation et de pr√©vention.

La mise en place cette application, pourrait nous permettre pr√©senter le produit √† des assurances tout en mettant en avant les ajouts qu'on fait par rapport √† la m√©thode classique.

Nous aspirons ainsi √† mettre √† la disposition des utilisateurs une interface facile, simple, automatis√© et bas√© sur de l'int√©lligence, sp√©cialement entrain√© dans le domaine.

## Donn√©es d'entrainement

Le projet s‚Äôappuie sur un jeu de donn√©es issu d‚Äôun portefeuille d‚Äôassurance automobile, contenant 26 383 lignes correspondant √† des enregistrements contractuels.

√Ä l‚Äôorigine, le jeu de donn√©es comprenait **12 variables principales**, d√©crivant essentiellement :

*   l‚Äôidentification des contrats et des factures (ex. *num\_contrat*, *Num\_facture*) ;
*   les informations temporelles (*datedeb*, *datefin*, *datcpt*, *exe*) ;
*   les montants de prime (*Prime*) ;
*   la nature de l‚Äôop√©ration (*libop*) ;
*   le statut de renouvellement du contrat (*renewed*).

Afin de r√©pondre aux objectifs analytiques et pr√©dictifs du projet, la base a √©t√© enrichie par **ing√©nierie de variables**. Plusieurs variables d√©riv√©es ont √©t√© construites, notamment :

**Variables de tarification et de dur√©e**

*   *nb\_jour\_couv*
*   *prime\_par\_jour*
*   *prime\_annualisee*
*   *log\_prime*
*   *anciennete\_contrat\_jours*
*   *anciennete\_client\_en\_jours*

**Variables contractuelles et comportementales**

*   *is\_avenant*
*   *is\_affaire\_nouvelle*
*   *is\_terme*
*   *nb\_impayes*
*   *retard\_paiement\_moyen\_jours*

**Variables li√©es au risque et √† la sinistralit√©**

*   *nb\_sinistres\_passe*
*   *cout\_sinistres\_passe*
*   *claim\_frequency*
*   *average\_claim\_cost*
*   *loss\_ratio*
*   *severity\_rate*

**Scores et indicateurs avanc√©s**

*   *client\_risk\_score*
*   *client\_profitability*
*   *technical\_margin*

√Ä l‚Äôissue de cette phase d‚Äôenrichissement, la base finale comprend 44 variables, qui constitue le socle utilis√© pour l‚Äôanalyse descriptive, le moteur NLQ, la g√©n√©ration d‚Äôinsights et les mod√®les pr√©dictifs de scoring client et de risque.

## Approche generale et architecture

Le projet repose sur 4 piliers obligatoires
1.  Pr√©paration & qualit√© des donn√©es
2.  Moteur NLQ intelligent (nous avons choisi OPENIA)
3.  AI insight
4.  Mod√®les pr√©dictifs & scoring client

et d‚Äôautres compl√©mentaires pour le traitement de donn√©es int√©lligent, etc.

### Pr√©paration & qualit√© des donn√©es

Le module de traitement des donn√©es repr√©sente le c≈ìur analytique de la plateforme d√©di√©e au secteur de l'assurance. Son architecture est con√ßue pour transformer des donn√©es brutes en informations structur√©es et actionnables via une m√©thodologie scientifique rigoureuse. Le syst√®me v√©rifie syst√©matiquement la pr√©sence de donn√©es avant d'autoriser l'acc√®s aux fonctionnalit√©s, garantissant ainsi l'int√©grit√© des op√©rations. Il priorise l'utilisation de donn√©es d√©j√† trait√©es, tout en conservant la capacit√© de travailler sur les donn√©es originales, assurant ainsi une flexibilit√© optimale dans le flux de travail.

L'initialisation repose sur un moteur de traitement scientifique, la classe `DataProcessingEngine`, dont l'√©tat est persist√© tout au long de la session utilisateur. Cette approche maintient la coh√©rence du contexte analytique et optimise les performances en √©vitant les r√©initialisations inutiles. L'ensemble des fonctionnalit√©s est organis√© en quatre phases distinctes accessibles via une interface onglets, offrant une progression logique du traitement.

La premi√®re phase, l'analyse scientifique, d√©ploie une batterie de tests statistiques avanc√©s pour caract√©riser automatiquement la nature des donn√©es. Elle identifie les types de variables, √©value les distributions via des tests de normalit√© comme Shapiro-Wilk et Anderson-Darling, et g√©n√®re une m√©trologie compl√®te incluant des indicateurs de qualit√© et de compl√©tude. Chaque variable b√©n√©ficie d'un profil statistique d√©taill√© qui en pr√©sente les caract√©ristiques fondamentales.

La seconde phase concerne le pr√©traitement intelligent, offrant trois strat√©gies adaptatives : une approche conservative qui privil√©gie l'int√©grit√© des donn√©es originales, une strat√©gie √©quilibr√©e recherchant un compromis optimal, et une m√©thode aggressive orient√©e vers la pr√©paration pour le machine learning. Ce traitement inclut la gestion des valeurs manquantes, la d√©tection d'anomalies et la normalisation adaptative, le tout avec un syst√®me de pr√©servation des types de donn√©es assurant la coh√©rence s√©mantique.

La troisi√®me phase se concentre sur la d√©tection automatique de variables cibles, combinant analyse s√©mantique et crit√®res statistiques. Le moteur examine la terminologie des colonnes, √©value la cardinalit√© et l'√©quilibre des distributions, et filtre les variables peu adapt√©es √† la mod√©lisation. Des recommandations personnalis√©es et des visualisations adapt√©es sont g√©n√©r√©es pour guider la s√©lection.

La quatri√®me phase propose une exploration statistique compl√®te avec un haut degr√© de personnalisation. Les utilisateurs peuvent filtrer, trier et explorer les donn√©es via des statistiques d√©taill√©es et des visualisations interactives adapt√©es √† chaque type de variable. Les fonctionnalit√©s d'export permettent de sauvegarder les r√©sultats dans des formats standardis√©s pour documentation ou int√©gration externe.

Sur le plan technique, le module dispose d'une gestion d'√©tat sophistiqu√©e qui conserve les r√©sultats interm√©diaires entre les √©tapes de traitement. Son syst√®me de gestion d'erreurs fournit des retours utilisateur clairs tout en conservant des informations techniques pour le d√©bogage. L'interface est optimis√©e pour une navigation intuitive avec des retours visuels imm√©diats et des indicateurs de progression.

L'ensemble orchestre un pipeline de traitement s√©quentiel mais flexible, transformant le traitement des donn√©es en un processus scientifique guid√©. Cette approche m√©thodique accompagne l'utilisateur depuis l'exploration initiale jusqu'√† la pr√©paration pour la mod√©lisation avanc√©e, tout en assurant la tra√ßabilit√© et la reproductibilit√© des traitements appliqu√©s, r√©pondant ainsi aux exigences sp√©cifiques du domaine de l'assurance.
### NLQ Engine

**R√©volutionner l'Acc√®s aux Donn√©es pour un Avantage Comp√©titif**

Le NLQ (Natural Language Query) Engine est bien plus qu'un simple moteur de recherche ; c'est un catalyseur strat√©gique. En transformant l'acc√®s complexe aux donn√©es en une interaction conversationnelle intuitive, il permet √† chaque utilisateur, quel que soit son niveau technique, d'extraire des informations importantes . Cette capacit√© √† interroger vos donn√©es et m√©tadonn√©es en langage naturel se traduit par des gains d'efficacit√© op√©rationnelle, une prise de d√©cision acc√©l√©r√©e et un avantage concurrentiel ind√©niable, en transformant les requ√™tes en insights actionnables.

*   **Acc√®s √©largi aux donn√©es** : mise √† disposition d‚Äôoutils permettant aux √©quipes d‚Äôinterroger les donn√©es sans comp√©tences techniques avanc√©es, afin de r√©duire les d√©pendances aux √©quipes sp√©cialis√©es et d‚Äôacc√©l√©rer l‚Äôexploration des informations.
*   **Exploitation des bases de donn√©es** : utilisation des donn√©es existantes pour produire des analyses statistiques, des indicateurs et des mod√®les pr√©dictifs, dans le but d‚Äôexploiter les informations disponibles de mani√®re plus compl√®te.
*   **Aide √† la d√©cision bas√©e sur les donn√©es** : production de r√©ponses structur√©es et contextualis√©es √† partir des donn√©es disponibles, afin de soutenir les processus de d√©cision avec des √©l√©ments mesurables et v√©rifiables.

**Catalyseur de Performance et d'Avantage Comp√©titif**

Le NLQ Engine est strat√©giquement con√ßu pour transformer la mani√®re dont votre organisation interagit avec ses donn√©es, en offrant des fonctionnalit√©s cl√©s qui se traduisent directement par un retour sur investissement (ROI) tangible. Il ne se contente pas de r√©pondre aux questions ; il g√©n√®re des explications contextuelles et des formats de r√©ponse optimis√©s, essentiels pour une compr√©hension approfondie et une prise de d√©cision √©clair√©e, propulsant ainsi l'efficacit√© op√©rationnelle et la comp√©titivit√©.

**Optimisation des Insights et de la R√©activit√©**

*   **Synth√®ses Ex√©cutives Impactantes** : Des r√©ponses courtes et concises pour une identification rapide des tendances critiques et une prise de d√©cision strat√©gique sans d√©lai.
*   **Analyses D√©taill√©es Approfondies** : Des rapports exhaustifs et nuanc√©s, permettant des diagnostics pr√©cis et l'√©laboration de strat√©gies bas√©es sur des donn√©es v√©rifi√©es.
*   **D√©monstrations Interactives** : Visualisez et manipulez les donn√©es en temps r√©el pour une meilleure compr√©hension des corr√©lations et de l'identification d'opportunit√©s cach√©es, acc√©l√©rant l'adoption des solutions.

Cette capacit√© unique √† int√©grer directement vos donn√©es et m√©tadonn√©es assure une flexibilit√© op√©rationnelle maximale et une personnalisation sans pr√©c√©dent des requ√™tes, vous permettant d'adapter pr√©cis√©ment l'analyse √† vos objectifs business et de d√©couvrir des insights qui garantissent un avantage comp√©titif durable.

![Architecture de l'application](NLP.png)
**_Figure 1: Architecture de l'application_**

**S√©curit√© et Confidentialit√© : Un Avantage Comp√©titif Strat√©gique avec le NLQ Engine**

La s√©curit√© et la confidentialit√© des donn√©es ne sont plus de simples exigences, mais des piliers fondamentaux pour la croissance et la r√©putation de votre entreprise. Au c≈ìur de la conception du NLQ Engine r√©side un engagement ferme √† prot√©ger vos actifs informationnels √† chaque √©tape de leur exploitation.

C‚Äôest dans cette logique que le NLQ Engine repose sur un principe fondamental : la s√©paration stricte entre les donn√©es sensibles et les donn√©es exploitables. Lors de l‚Äôutilisation de l‚Äôapplication, deux types d‚Äôentr√©es sont syst√©matiquement d√©finis :

1.  La donn√©e originale, brute et sensible est fournie initialement au syst√®me afin de lui permettre de comprendre le contexte, la structure et la logique m√©tier associ√©e. Cette donn√©e est utilis√©e uniquement comme r√©f√©rence de compr√©hension. Une fois cette phase effectu√©e, elle est imm√©diatement isol√©e, puis supprim√©e des espaces de traitement actif, afin de garantir la confidentialit√© et de limiter toute exposition inutile. Le syst√®me ne conserve pas la donn√©e brute elle-m√™me, mais uniquement son historique logique et structurel : relations, sch√©mas, d√©pendances, r√®gles implicites et m√©tadonn√©es associ√©es. C‚Äôest sur cette base que le moteur construit son raisonnement. Autrement dit, le chat ne raisonne jamais √† partir de la donn√©e sensible elle-m√™me, mais √† partir de l‚Äôempreinte informationnelle qu‚Äôelle a laiss√©e :sa structure, son organisation, ses relations, ses sch√©mas d‚Äôusage.
    Cette approche permet de garantir que :
    *   les informations confidentielles ne sont jamais directement expos√©es.
    *   la logique m√©tier reste exploitable.
    *   la continuit√© du raisonnement est assur√©e.
    *   l‚Äôhistorique conversationnel reste coh√©rent et pertinent.
    *   la confidentialit√© est pr√©serv√©e √† long terme.
    Ainsi, m√™me apr√®s suppression des donn√©es sensibles, le syst√®me continue √† fonctionner efficacement en se basant uniquement sur l‚Äôhistorique logique s√©curis√©, garantissant √† la fois performance, tra√ßabilit√© et protection des informations critiques.
2.  Une couche de m√©tadonn√©es, sur laquelle l‚Äôensemble des traitements, analyses et interactions seront effectu√©s.
    Cette architecture permet de garantir que les op√©rations ne s‚Äôeffectuent jamais directement sur les donn√©es critiques, mais uniquement sur leur repr√©sentation s√©curis√©e. Ce m√©canisme r√©duit drastiquement les risques de fuite, d‚Äôexposition ou de mauvaise manipulation, tout en maintenant une capacit√© d‚Äôanalyse compl√®te et performante.
    Nous d√©ployons des protocoles de s√©curit√© avanc√©s et des architectures robustes afin de garantir une protection maximale de toutes les informations sensibles. Cette approche assure non seulement une conformit√© rigoureuse et une r√©duction significative des risques, mais renforce √©galement la confiance de vos clients et partenaires, transformant la s√©curit√© en un v√©ritable levier de valeur et un avantage comp√©titif durable.
    *   **Protection des Actifs Critiques** : mise en ≈ìuvre de m√©canismes de s√©curit√© avanc√©s fond√©s sur l‚Äôisolation des donn√©es sensibles et leur exploitation indirecte via des m√©tadonn√©es s√©curis√©es. Cette approche permet une protection proactive des informations strat√©giques et de la propri√©t√© intellectuelle, tout en garantissant leur int√©grit√© et leur disponibilit√© pour la continuit√© des op√©rations.
    *   **Conformit√© R√©glementaire Optimis√©e** : int√©gration native des exigences r√©glementaires (RGPD, HIPAA, etc.) gr√¢ce √† une architecture qui limite l‚Äôexposition directe des donn√©es personnelles et sensibles. Cette s√©paration structurelle entre donn√©es sources et donn√©es exploit√©es r√©duit les risques juridiques et financiers, tout en facilitant l‚Äôacc√®s √† de nouveaux march√©s.
    *   **Gestion des Acc√®s S√©curis√©e** : authentification renforc√©e et gestion fine des privil√®ges pour chaque interaction. L‚Äôacc√®s aux donn√©es sensibles est strictement contr√¥l√©, tandis que les utilisateurs travaillent exclusivement sur des repr√©sentations s√©curis√©es (m√©tadonn√©es). Cela garantit la confidentialit√©, emp√™che toute utilisation non conforme et prot√®ge l‚Äôint√©grit√© des processus m√©tiers.

### Insight AI

**D√©bloquez une Valeur Strat√©gique avec la Visualisation des Donn√©es**

Insight AI n'est pas seulement une solution d'analyse descriptive, c'est votre avantage concurrentiel. En transformant des volumes massifs de donn√©es brutes en visualisations claires et intelligentes, nous permettons √† votre organisation d'acc√©l√©rer la prise de d√©cision, d'optimiser l'efficacit√© op√©rationnelle et de maximiser le retour sur investissement. Identifiez les tendances √©mergentes, anticipez les d√©fis et saisissez des opportunit√©s strat√©giques avec une pr√©cision sans pr√©c√©dent : des tableaux de bord interactifs et des graphiques r√©actifs qui transforment l'exploration des donn√©es en un processus intuitif et rapide, alimentant des d√©cisions commerciales avis√©es, et des synth√®ses claires et des statistiques descriptives robustes pour une compr√©hension imm√©diate de la performance, permettant une identification proactive des leviers de croissance.

**De l'Analyse Explicative √† la D√©cision Strat√©gique**

Au-del√† de la simple visualisation, Insight AI transforme vos donn√©es brutes en une intelligence explicative et actionnable. Notre solution va au-del√† des chiffres pour r√©v√©ler les facteurs cl√©s influen√ßant vos performances, vous offrant une compr√©hension profonde et pr√©dictive. Cela permet √† votre organisation de prendre des d√©cisions √©clair√©es qui maximisent le retour sur investissement, optimisent l'efficacit√© op√©rationnelle et forgent un avantage concurrentiel durable. En ces points, on a :

*   **Intelligence Actionnable** : des explications claires et approfondies des r√©sultats, transformant les donn√©es en leviers de performance mesurables.
*   **Optimisation Strat√©gique** : des insights concrets qui guident vos strat√©gies clients, garantissant des d√©cisions pr√©cises pour une croissance exponentielle.

### Mod√®les Pr√©dictifs

Notre suite int√®gre des mod√®les pr√©dictifs de pointe, m√©ticuleusement √©labor√©s pour d√©crypter les tendances √©mergentes et anticiper les comportements futurs. En exploitant l'int√©gralit√© de vos donn√©es historiques, ces mod√®les d√©livrent des projections d'une pr√©cision in√©gal√©e, vous conf√©rant un avantage strat√©gique d√©terminant pour une prise de d√©cision proactive, une optimisation des ressources et une croissance durable. C'est l'outil essentiel pour transformer l'incertitude en opportunit√©, assurer un retour sur investissement tangible et consolider votre position de leader sur le march√©.

> Anticiper l'avenir n'est plus une conjecture, mais une ma√Ætrise strat√©gique des donn√©es pour sculpter votre succ√®s et distancer la concurrence.

**D√©bloquez la Croissance Future : La M√©canique de Nos Mod√®les Pr√©dictifs**

Nos mod√®les pr√©dictifs de pointe transforment vos donn√©es historiques en une feuille de route strat√©gique. En s'appuyant sur des algorithmes sophistiqu√©s, ils d√©tectent les sch√©mas, corr√©lations et causalit√©s latentes, offrant des projections pr√©cises pour anticiper les ventes, optimiser les strat√©gies client et mitiger les risques op√©rationnels. Cette capacit√© √† visualiser l'avenir vous conf√®re un avantage concurrentiel d√©cisif, garantissant des d√©cisions √©clair√©es et un retour sur investissement maximal.
Le processus de mod√©lisation est organis√© en trois phases distinctes et compl√©mentaires, chacune adressant une dimension sp√©cifique de l'analyse pr√©dictive.

L'analyse exploratoire sert de fondation √† tout le processus de mod√©lisation. Cette phase ne se contente pas d'une simple visualisation ; elle impl√©mente une caract√©risation automatique des variables potentielles. Le syst√®me examine chaque colonne pour d√©terminer sa nature statistique : il distingue les variables cat√©gorielles binaires (2 classes), multi-classes (jusqu'√† 20 classes), et les variables num√©riques continues. Pour chaque type d√©tect√©, il g√©n√®re des visualisations adapt√©es : diagrammes circulaires pour les variables binaires, diagrammes en barres pour les multi-classes, et histogrammes avec statistiques descriptives pour les variables num√©riques. L'analyse de corr√©lation va au-del√† des repr√©sentations traditionnelles en fournissant une heatmap interactive accompagn√©e d'un classement hi√©rarchique des dix associations les plus fortes d√©tect√©es dans les donn√©es. Cette approche permet √† l'utilisateur d'identifier rapidement les relations cl√©s et de s√©lectionner des variables pr√©dictives pertinentes pour les √©tapes ult√©rieures.

Le module de classification impl√©mente une cha√Æne de traitement sophistiqu√©e inspir√©e des bonnes pratiques du machine learning tout en conservant une accessibilit√© remarquable. La pr√©paration des donn√©es commence par une validation rigoureuse des entr√©es, excluant automatiquement les variables non utilisables comme les dates ou les colonnes avec trop de cat√©gories. Le syst√®me applique un encodage one-hot intelligent aux variables cat√©gorielles, avec une limite automatique sur le nombre de cat√©gories pour √©viter l'explosion dimensionnelle. La gestion des valeurs manquantes propose trois strat√©gies configurables : imputation par m√©diane, imputation par moyenne, ou suppression des lignes incompl√®tes. Une √©tape de filtrage de variance √©limine automatiquement les variables quasi-constantes qui n'apporteraient aucune information discriminative.

L'entra√Ænement des mod√®les de classification supporte quatre algorithmes principaux, chacun optimis√© pour le domaine de l'assurance. Le Random Forest Classifier est impl√©ment√© avec des hyperparam√®tres adapt√©s aux donn√©es de taille moyenne, incluant des m√©canismes automatiques d'√©quilibrage des classes via le param√®tre class_weight. XGBoost offre des performances avanc√©es avec une gestion native des donn√©es d√©s√©quilibr√©es via scale_pos_weight. La r√©gression logistique fournit une option interpr√©table avec r√©gularisation L2, tandis que Gradient Boosting propose un √©quilibre entre performance et complexit√©. Chaque mod√®le b√©n√©ficie d'une optimisation automatique des hyperparam√®tres via recherche en grille adaptative qui ajuste la complexit√© de la recherche selon la taille des donn√©es disponibles.

L'√©valuation des mod√®les de classification d√©passe les m√©triques basiques. Outre l'accuracy, la pr√©cision, le rappel et le F1-score calcul√©s avec pond√©ration adapt√©e au type de probl√®me, le syst√®me g√©n√®re des matrices de confusion interactives avec visualisation thermique. Pour les probl√®mes de classification binaire, il produit des courbes ROC avec calcul d'AUC et des courbes pr√©cision-rappel. L'importance des variables, lorsqu'elle est disponible (notamment pour les mod√®les arborescents), est pr√©sent√©e sous forme de graphique en barres horizontales class√©es et d'un tableau d√©taill√© exportable. Le module inclut √©galement une analyse des erreurs de pr√©diction avec √©chantillonnage des cas mal class√©s pour investigation plus approfondie.

Le module de r√©gression aborde la pr√©diction de variables continues avec une m√©thodologie adapt√©e aux sp√©cificit√©s des donn√©es d'assurance. La pr√©paration des donn√©es inclut un traitement sp√©cifique des outliers avec trois approches configurables : conservation pour pr√©server l'int√©grit√© des donn√©es, suppression pour √©liminer les valeurs extr√™mes potentiellement nuisibles, ou winsorization pour limiter leur influence tout en conservant l'information. La normalisation propose quatre m√©thodes : standardisation (adapt√©e aux donn√©es gaussiennes), min-max (pour les donn√©es born√©es), robuste (r√©sistante aux outliers), ou aucune transformation pour les algorithmes insensibles √† l'√©chelle.

Les algorithmes de r√©gression impl√©ment√©s incluent Random Forest Regressor avec param√©trage adapt√© aux probl√®mes de pr√©diction num√©rique, XGBoost Regressor optimis√© pour la performance computationnelle, r√©gression lin√©aire pour son interpr√©tabilit√© et sa rapidit√©, et Gradient Boosting Regressor comme alternative √©quilibr√©e. Chaque algorithme b√©n√©ficie d'une optimisation d'hyperparam√®tres sp√©cifique : recherche de la profondeur optimale et du nombre d'arbres pour les m√©thodes ensemblistes, optimisation du taux d'apprentissage et de la r√©gularisation pour les m√©thodes de boosting.

L'√©valuation des mod√®les de r√©gression utilise une batterie compl√®te de m√©triques adapt√©es aux probl√®mes de pr√©diction num√©rique. Le R¬≤ mesure la proportion de variance expliqu√©e, le RMSE et MAE quantifient l'erreur absolue avec diff√©rentes sensibilit√©s aux outliers, et le MAPE exprime l'erreur relative pour les comparaisons inter-datasets. Les visualisations incluent des graphiques de dispersion comparant pr√©dictions et valeurs r√©elles avec ligne de r√©f√©rence id√©ale, des histogrammes de distribution des erreurs, et des QQ-plots pour v√©rifier la normalit√© des r√©sidus. L'importance des variables est calcul√©e pour les mod√®les arborescents et pr√©sent√©e de mani√®re hi√©rarchique.

L'architecture technique sous-jacente assure la coh√©rence et la reproductibilit√© des analyses. Le syst√®me maintient un √©tat complet de chaque mod√©lisation dans la session utilisateur, permettant de naviguer entre les diff√©rentes phases sans perte d'information. Les fonctions de pr√©paration des donn√©es incluent des validations robustes et des m√©canismes de fallback pour g√©rer les cas limites. L'export des mod√®les sauvegarde non seulement l'algorithme entra√Æn√© mais √©galement l'ensemble des transformations appliqu√©es aux donn√©es, garantissant que les m√™mes pr√©traitements seront appliqu√©s lors de l'utilisation en production. La g√©n√©ration automatique de code de reproduction pour chaque mod√®le facilite le transfert vers des environnements de d√©ploiement et assure la tra√ßabilit√© compl√®te du processus analytique.

Cette approche modulaire et m√©thodique transforme la mod√©lisation pr√©dictive d'une t√¢che technique complexe en un processus guid√© accessible aux analystes m√©tier tout en conservant la rigueur n√©cessaire aux data scientists. Elle int√®gre les avanc√©es th√©oriques r√©centes en apprentissage automatique tout en restant ancr√©e dans les besoins pratiques du secteur de l'assurance, offrant ainsi une plateforme compl√®te depuis l'exploration des donn√©es jusqu'au d√©ploiement de mod√®les robustes et interpr√©tables.

**Maximiser Performance et Rentabilit√© avec l'IA Pr√©dictive**

L'int√©gration strat√©gique des mod√®les pr√©dictifs n'est plus un avantage, c'est une n√©cessit√© imp√©rative pour toute entreprise visant l'excellence op√©rationnelle et une croissance soutenue. Notre suite d'IA transforme vos donn√©es brutes en informations exploitables, vous permettant d'optimiser radicalement l'allocation de vos ressources, d'affiner vos campagnes marketing pour des r√©sultats sans pr√©c√©dent et d'anticiper les risques pour une meilleure att√©nuation. En offrant une compr√©hension approfondie des tendances futures, nos solutions garantissent un retour sur investissement (ROI) maximal, r√©duisent les co√ªts op√©rationnels et propulsent l'exp√©rience client vers des sommets in√©gal√©s. C'est la cl√© pour transformer vos donn√©es en un avantage concurrentiel durable, stimuler une croissance exponentielle et asseoir votre leadership sur le march√©.
On a int√©gr√© plusieurs mod√®les dans l'application, cela permet √† l'utilisateur d'avoir un large choix pour mieux adapter son √©tude.

**Le Random Forest**

Le **Random Forest** est un mod√®le d‚Äôapprentissage ensembliste qui consiste √† combiner un grand nombre d‚Äôarbres de d√©cision construits de mani√®re ind√©pendante et al√©atoire afin d‚Äôam√©liorer la qualit√© des pr√©dictions. Son principe de fonctionnement repose sur l‚Äôintroduction volontaire de l‚Äôal√©a √† deux niveaux : d‚Äôune part, chaque arbre est entra√Æn√© sur un √©chantillon bootstrap des donn√©es, et d‚Äôautre part, √† chaque n≈ìud de l‚Äôarbre, seule une s√©lection al√©atoire de variables est consid√©r√©e pour d√©terminer le meilleur d√©coupage, g√©n√©ralement en maximisant une r√©duction d‚Äôimpuret√© (comme l‚Äôerreur quadratique en r√©gression). Une fois les arbres construits, la pr√©diction finale est obtenue par agr√©gation des pr√©dictions individuelles, sous forme de moyenne en r√©gression ou de vote majoritaire en classification. Math√©matiquement, la for√™t approxime la fonction cible en moyennant les pr√©dictions des arbres, ce qui permet de r√©duire fortement la variance tout en conservant un biais faible. Cette structure rend le Random Forest particuli√®rement robuste aux non-lin√©arit√©s, aux interactions complexes entre variables et au bruit des donn√©es, ce qui explique son excellente performance pratique, par exemple pour la pr√©diction du risque client en assurance, o√π chaque arbre apprend des r√®gles diff√©rentes et la for√™t fournit un score final stable et fiable.

**XGBoost**

L‚Äô**XGBoost (eXtreme Gradient Boosting)** est une m√©thode de **boosting d‚Äôarbres de d√©cision r√©gularis√©e**, initialement propos√©e par Chen et Guestrin (2016), qui s‚Äôest impos√©e comme l‚Äôun des algorithmes les plus performants pour l‚Äôanalyse pr√©dictive sur de grands jeux de donn√©es. Son principe repose sur la construction s√©quentielle d‚Äôarbres de r√©gression, chaque nouvel arbre √©tant ajout√© pour corriger les erreurs des arbres pr√©c√©dents, tout en minimisant une **fonction objectif r√©gularis√©e** combinant une fonction de perte convexe et des p√©nalit√©s de complexit√© sur la structure des arbres. L‚Äôoptimisation est r√©alis√©e √† l‚Äôaide d‚Äôune **approximation de Taylor d‚Äôordre deux**, exploitant √† la fois les gradients et les hessiens de la fonction de perte, ce qui permet une optimisation efficace et pr√©cise.

L‚Äôarticle de Yang Guang (Y.Guang, Generalized XGBoost Method, 2022) souligne toutefois une **limite th√©orique importante** du XGBoost classique : l‚Äôexigence de convexit√© de la fonction de perte, condition n√©cessaire pour garantir la convergence de l‚Äôalgorithme. Or, dans de nombreuses applications r√©elles, notamment en **assurance non-vie**, les variables √† mod√©liser suivent des distributions asym√©triques ou √† queues √©paisses, pour lesquelles des fonctions de perte non convexes (issues de vraisemblances param√©triques) sont plus appropri√©es. Pour r√©pondre √† cette limite, l‚Äôauteur propose une **g√©n√©ralisation de XGBoost**, qui assouplit la contrainte de convexit√© et permet l‚Äôutilisation de fonctions de perte plus g√©n√©rales, √† condition qu‚Äôelles soient deux fois d√©rivables et poss√®dent un minimum unique.

Enfin, l‚Äôarticle √©tend XGBoost √† un cadre **multi-param√©trique**, dans lequel plusieurs param√®tres d‚Äôune m√™me distribution (par exemple la moyenne et la dispersion) sont estim√©s simultan√©ment via des arbres distincts mais coordonn√©s. Cette extension rapproche XGBoost des mod√®les statistiques distributionnels tout en conservant la flexibilit√© des m√©thodes de machine learning, offrant ainsi un cadre puissant pour la mod√©lisation probabiliste et la tarification en assurance.

**La r√©gression logistique**

 La r√©gression logistique est un mod√®le probabiliste destin√© √† expliquer une variable binaire ùëå‚àà{0,1} √† partir de variables explicatives 
ùëã. Elle mod√©lise la probabilit√© conditionnelle:

$$P(Y=1‚à£X)= 1/(1+e‚àíXŒ≤)$$‚Äã

Cette formulation repose sur l‚Äôhypoth√®se que le log-odds (logarithme du rapport de probabilit√©s) est une fonction lin√©aire des variables explicatives :

$$log(P(Y=1‚à£X)/ (1‚àíP(Y=1‚à£X)‚Äã))=XŒ≤$$

## Timeline du projet

![Agile Project Plan](plan_agile.png)
**_Figure 2: Agile Project Plan_**

Notre plan de travail agile, structur√© sur un sprint de six jours (du 13 au 19 janvier 2026), est con√ßu pour garantir la livraison incr√©mentale d'une solution fonctionnelle √† forte valeur m√©tier. Le projet d√©bute par une journ√©e essentielle de cadrage et de fondations, durant laquelle Ibrahima, en tant que chef d'√©quipe et responsable du moteur NLQ, d√©finit avec l'√©quipe la vision, l'architecture technique et les interfaces de communication communes, s'assurant que tous les modules pourront dialoguer. Mariam, responsable du moteur d'insights, identifie les indicateurs m√©tier cl√©s et pr√©pare les donn√©es, tandis que Babacar, en charge du mod√®le pr√©dictif, s√©lectionne l'algorithme de scoring initial. De son c√¥t√©, Aya √©labore les premi√®res maquettes de l'interface utilisateur. Cette phase initiale est cruciale pour aligner l'√©quipe sur les fonctionnalit√©s ¬´ Must ¬ª incontournables.

Les deuxi√®me et troisi√®me jours sont consacr√©s au d√©veloppement parall√®le et √† l'int√©gration des composants de base. Chaque membre travaille simultan√©ment sur son c≈ìur de m√©tier : Ibrahima d√©veloppe le moteur de compr√©hension du langage naturel et l'API Gateway ; Mariam b√¢tit le pipeline de nettoyage des donn√©es et le g√©n√©rateur d'insights ; Babacar entra√Æne et d√©ploie son mod√®le de pr√©diction ; et Aya construit l'interface de chat et de visualisation. L'objectif du troisi√®me jour, la ¬´ consolidation Must ¬ª, est d'int√©grer tous ces blocs pour obtenir un produit minimal viable (MVP) parfaitement fonctionnel et stable. Cette approche parall√®le et int√©grative nous permet de tester chaque brique progressivement et d'√©viter les goulots d'√©tranglement.

Une fois le noyau stable, les quatri√®me et cinqui√®me jours sont d√©di√©s aux am√©liorations ¬´ Nice to Have ¬ª et aux fonctionnalit√©s ¬´ Bonus ¬ª. Ibrahima peut enrichir le NLQ avec du contexte conversationnel, Mariam ajoute un syst√®me d'alertes et des visualisations avanc√©es, Babacar int√®gre l'explicabilit√© du mod√®le, et Aya peaufine l'exp√©rience utilisateur avec des animations et un mode pr√©sentation. Ces ajouts, conditionn√©s √† la solidit√© du c≈ìur, apportent une vraie plus-value et un ¬´ wow factor ¬ª pour la d√©monstration. Enfin, le sixi√®me jour est enti√®rement consacr√© √† la pr√©paration et au rodage d'une pr√©sentation percutante, o√π chacun pr√©sente sa contribution dans un r√©cit coh√©rent qui met en lumi√®re la valeur m√©tier de notre solution.

## Choix des outils, technologies et packages

Dans le cadre de ce projet, nous avons fait le choix d‚Äôune stack technologique moderne, l√©g√®re et orient√©e data & IA, permettant un d√©veloppement rapide, modulaire et facilement d√©montrable, tout en restant proche des standards professionnels utilis√©s en entreprise avec des fonctions vari√©es et surtout s√©curis√©es.

**Langage principal : Python**

Nous avons choisi `Python` comme langage principal pour les raisons suivantes :

*   science et de l‚Äôintelligence artificielle ;
*   richesse de l‚Äô√©cosyst√®me de biblioth√®ques ;
*   rapidit√© de prototypage, essentielle dans un hackathon ;
*   facilit√© d‚Äôint√©gration entre donn√©es, mod√®les et interfaces.
*   forte adoption dans le domaine de la data

Comme environnement de codage, nous avons choisi *Pycharm Community Edition* 2025 avec la version et directement sur un Github des membres `3.14, 3.13 et 3.12 de python`.

![Quelques packages](package.png)

**_Figure 3: Quelques packages_**

Le module (`numpy`,`pandas`) permet d‚Äôexpliquer les scores produits par les mod√®les, d‚Äôidentifier les variables les plus influentes et de transformer les r√©sultats techniques en recommandations m√©tier claires. L‚Äôobjectif est de renforcer la confiance des d√©cideurs dans les r√©sultats produits par l‚Äôintelligence artificielle.

`Streamlit` a √©t√© choisi pour sa simplicit√© et sa capacit√© √† produire rapidement des interfaces interactives. Les biblioth√®ques de visualisation permettent de repr√©senter les indicateurs cl√©s, les scores et les r√©sultats des mod√®les sous forme de graphiques compr√©hensibles, facilitant ainsi l‚Äôinterpr√©tation m√©tier des analyses (`plotly`,`seaborn`).

Plusieurs mod√®les ont √©t√© test√©s, notamment le Random Forest et le Gradient Boosting :`xgboot`, `scikit-learn`, `joblib`,etc. Ces algorithmes sont bien adapt√©s aux probl√©matiques de classification, comme la pr√©diction du renouvellement ou de la r√©siliation des contrats, et offrent un bon compromis entre performance et interpr√©tabilit√©.

Pour l'entrainement du moteur de recherche "CHATBOT", nous avons choisi d'utiliser l'OpenAI pour la g√©n√©ration de la cl√© API qui fonctionne avec *CHATGPT4*.

Ainsi, tout ce qui est fait, reste en local et ceci permet de g√©rer le c√¥t√© "s√©curit√©" de l'application.

![Generation : API key](openai.png)
**_Figure 4: Generation : API key_**

**Nous vous mettons en Copie une d√©monstration du fonctionnement de l'application (m√™me si cette derni√®re n'est pas finaliser encore)**

---
## R√©f√©rences

[1](https://www.narsa.ma/sites/default/files/2024-11/Rapport%20de%20la%20SR%202022%20V5_231020_140005_compressed.pdf%7D$) NARSA. *Rapport annuel 2022 sur la s√©curit√© routi√®re au Maroc*. Observatoire National de la S√©curit√© Routi√®re.

Hosmer, Lemeshow & Sturdivant (2013), Applied Logistic Regression, Wiley  [4](https://books.google.co.ma/books?hl=fr&lr=&id=bRoxQBIZRd4C&oi=fnd&pg=PR13&dq=Hosmer,+Lemeshow+%26+Sturdivant(2013),+Applied+Logistic+Regression,+Wiley&ots=kM6SxpcSjb&sig=xreANOrsf7yA4bD7EkSMCblAMPg&redir_esc=y#v=onepage&q=Hosmer%2C%20Lemeshow%20%26%20Sturdivant%20(2013)%2C%20Applied%20Logistic%20Regression%2C%20Wiley&f=false)
